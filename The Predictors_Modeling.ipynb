{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1c82cd-a7a3-49c2-8fed-aad8554e40ed",
   "metadata": {},
   "source": [
    "#Team Members:\n",
    "#Gagana Uday Kumar - WOV796\n",
    "#Niharika Bandlamudi - HBZ194\n",
    "#Nupoor Karnik - JHR497\n",
    "#Munivenkataparthasai Madallapalli -PUA528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba2a98f-3b6b-4040-ab72-f92a2eaa6198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reading the necessary libraries: #base model\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import hstack \n",
    "import csv\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#seeding for randamziation:\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cbd166c-9ba6-4c33-8770-9f12ae005771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reading raw data from Final_Annotationsby_Detectives_GSD.csv Golden Standards dataset: \n",
    "#Feature and Label Variables:\n",
    "X_txt= []\n",
    "y= []\n",
    "\n",
    "# Loading data from CSVs:\n",
    "# Load the training datasets into two lists (X_txt will be a list of strings with features; \n",
    "# y will list of 0's and 1's with labels or classification):\n",
    "with open('./Gold Standards DataSet_D_SA.csv',encoding='iso-8859-1') as in_file:\n",
    "    iCSV = csv.reader(in_file, delimiter=',')\n",
    "    header=next(iCSV)\n",
    "    for row in iCSV:\n",
    "        X_txt.append(row[1])\n",
    "        y.append([int(value) for value in row[2:6]])\n",
    "        \n",
    "#print(len(X_txt))\n",
    "#print(X_txt)\n",
    "#print(len(y))\n",
    "#print(header[1:6],y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "617a88a1-a2d5-4d0b-8cb9-a9615d93877c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Split the data into training and test sets:\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_txt,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb541765-83d9-4625-8346-6ef04a6014e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Validation Score F1: 0.4110\n",
      "Macro Test Score F1: 0.4007\n",
      "Macro_Score Precision: 0.4137\n",
      "Macro_Score Recall: 0.3926\n",
      "Gold Standards- Technology Macro_Score F1: 0.8201\n",
      "Gold Standards- Ride Share Macro_Score F1: 0.2069\n",
      "Gold Standards- Food Delivery Macro_Score F1: 0.3492\n",
      "Gold Standards- Online Shopping Macro_Score F1: 0.2264\n",
      "\n",
      "Micro Validation Score F1: 0.5229\n",
      "Micro Test Score F1: 0.5010\n",
      "Micro_Score Precision: 0.5708\n",
      "Micro_Score Recall: 0.4464\n",
      "Gold Standards- Technology Micro_Score F1: 0.8319\n",
      "Gold Standards- Ride Share Micro_Score F1: 0.2078\n",
      "Gold Standards- Food Delivery Micro_Score F1: 0.2778\n",
      "Gold Standards- Online Shopping Micro_Score F1: 0.1522\n"
     ]
    }
   ],
   "source": [
    "#Base Modeling with all task 1 features and task 2 lables(without lexicon features implementation):\n",
    "#modeling with ngram_range=(1,1) & LogisticRegression with CountVectorizer: \n",
    "\n",
    "#converting list to matrix:\n",
    "vec=CountVectorizer(ngram_range=(1,1))\n",
    "X_train_matrix =vec.fit_transform(X_train) # This should be a matrix\n",
    "X_test_matrix=vec.transform(X_test)# This should be a matrix\n",
    "\n",
    "#converting list to array:\n",
    "ya_train=np.array(y_train)\n",
    "ya_test=np.array(y_test)\n",
    "#print(y_test.shape[1])\n",
    "\n",
    "#initializing logisticregression:\n",
    "log_reg=MultiOutputClassifier(LogisticRegression(random_state=42,solver='lbfgs', max_iter=2000))\n",
    "\n",
    "#params with c values:\n",
    "params= {\"estimator__C\": [0.0001, 0.001, 0.01, 0.1, 1, 10,100]}\n",
    "\n",
    "#initialize GridSearchCV with scoring f1_macro:\n",
    "\n",
    "init_grid_search_macro=GridSearchCV(log_reg,params,cv=5,scoring='f1_macro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_macro:\n",
    "init_grid_search_macro.fit(X_train_matrix,ya_train)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_macro_score = init_grid_search_macro.score(X_test_matrix,ya_test) \n",
    "validation_results_best_score=init_grid_search_macro.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Macro Validation Score F1: {:.4f}\".format(validation_results_best_score))\n",
    "print(\"Macro Test Score F1: {:.4f}\".format(validation_macro_score))\n",
    "\n",
    "#predciting on X_test data with scoring f1_macro:\n",
    "logistic_X_test_prediciton_macro=init_grid_search_macro.predict(X_test_matrix)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as macro parameter:\n",
    "precision_macro=precision_score(ya_test,logistic_X_test_prediciton_macro,average='macro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_macro = recall_score(ya_test,logistic_X_test_prediciton_macro,average='macro')\n",
    "print(\"Macro_Score Precision: {:.4f}\".format(precision_macro))\n",
    "print(\"Macro_Score Recall: {:.4f}\".format(recall_macro))\n",
    "for i in range(4):\n",
    "    #f1_macro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_macro])\n",
    "    f1_macro_i = f1_score(ya_test[:,i],logistic_X_test_prediciton_macro[:,i])\n",
    "    print(f\"{header[i+2]} Macro_Score F1: {f1_macro_i:.4f}\")\n",
    "    \n",
    "print()    \n",
    "    \n",
    "\n",
    "#initialize GridSearchCV with scoring f1_micro:\n",
    "\n",
    "init_grid_search_micro=GridSearchCV(log_reg,params,cv=5,scoring='f1_micro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_micro:\n",
    "init_grid_search_micro.fit(X_train_matrix,ya_train)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_micro_score = init_grid_search_micro.score(X_test_matrix,ya_test) \n",
    "validation_results_best_score_micro=init_grid_search_micro.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Micro Validation Score F1: {:.4f}\".format(validation_results_best_score_micro))\n",
    "print(\"Micro Test Score F1: {:.4f}\".format(validation_micro_score))\n",
    "\n",
    "# Get the score from the GridSearchCV \"best score\" with Micro f1:\n",
    "#print(\"Micro_Score Validation F1: {:.4f}\".format(validation_micro_score))\n",
    "\n",
    "#predciting on X_test data with scoring f1_micro:\n",
    "logistic_X_test_prediciton_micro=init_grid_search_micro.predict(X_test_matrix)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as micro parameter:\n",
    "precision_micro=precision_score(ya_test,logistic_X_test_prediciton_micro,average='micro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_micro = recall_score(ya_test,logistic_X_test_prediciton_micro,average='micro')\n",
    "print(\"Micro_Score Precision: {:.4f}\".format(precision_micro))\n",
    "print(\"Micro_Score Recall: {:.4f}\".format(recall_micro))\n",
    "for i in range(4):\n",
    "    #f1_micro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_micro])\n",
    "    f1_micro_i = f1_score(ya_test[:,i],logistic_X_test_prediciton_micro[:,i])\n",
    "    print(f\"{header[i+2]} Micro_Score F1: {f1_micro_i:.4f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c9867d1-c37d-433f-a698-a6770f3fe91e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Validation Score F1: 0.2106\n",
      "Macro Test Score F1: 0.2612\n",
      "Macro_Score Precision: 0.4455\n",
      "Macro_Score Recall: 0.2639\n",
      "Gold Standards- Technology Macro_Score F1: 0.7939\n",
      "Gold Standards- Ride Share Macro_Score F1: 0.0377\n",
      "Gold Standards- Food Delivery Macro_Score F1: 0.0988\n",
      "Gold Standards- Online Shopping Macro_Score F1: 0.1143\n",
      "\n",
      "Micro Validation Score F1: 0.4964\n",
      "Micro Test Score F1: 0.4881\n",
      "Micro_Score Precision: 0.6494\n",
      "Micro_Score Recall: 0.3910\n",
      "Gold Standards- Technology Micro_Score F1: 0.7839\n",
      "Gold Standards- Ride Share Micro_Score F1: 0.0377\n",
      "Gold Standards- Food Delivery Micro_Score F1: 0.0533\n",
      "Gold Standards- Online Shopping Micro_Score F1: 0.0968\n"
     ]
    }
   ],
   "source": [
    "#Base Modeling with all task 1 features and task 2 lables(without lexicon features implementation):\n",
    "#modeling with ngram_range=(1,5) & LogisticRegression with TfidfVectorizer: \n",
    "\n",
    "#converting list to matrix:\n",
    "vec_tfid=TfidfVectorizer(ngram_range=(1,5))\n",
    "X_train_matrix_tfid =vec_tfid.fit_transform(X_train) # This should be a matrix\n",
    "X_test_matrix_tfid=vec_tfid.transform(X_test)# This should be a matrix\n",
    "\n",
    "\n",
    "#converting list to array:\n",
    "ya_train_tfid=np.array(y_train)\n",
    "ya_test_tfid=np.array(y_test)\n",
    "#print(y_test.shape[1])\n",
    "\n",
    "#initializing logisticregression:\n",
    "log_reg_tfid=MultiOutputClassifier(LogisticRegression(random_state=42,solver='lbfgs', max_iter=2000))\n",
    "\n",
    "#params with c values:\n",
    "params_tfid= {\"estimator__C\": [0.0001, 0.001, 0.01, 0.1, 1, 10,100]}\n",
    "\n",
    "#initialize GridSearchCV with scoring f1_macro:\n",
    "\n",
    "init_grid_search_macro_tfid=GridSearchCV(log_reg_tfid,params_tfid,cv=5,scoring='f1_macro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_macro:\n",
    "init_grid_search_macro_tfid.fit(X_train_matrix_tfid,ya_train_tfid)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_macro_score_tfid = init_grid_search_macro_tfid.score(X_test_matrix_tfid,ya_test_tfid) \n",
    "validation_results_best_score_tfid=init_grid_search_macro_tfid.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Macro Validation Score F1: {:.4f}\".format(validation_results_best_score_tfid))\n",
    "print(\"Macro Test Score F1: {:.4f}\".format(validation_macro_score_tfid))\n",
    "\n",
    "#predciting on X_test data with scoring f1_macro:\n",
    "logistic_X_test_prediciton_macro_tfid=init_grid_search_macro_tfid.predict(X_test_matrix_tfid)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as macro parameter:\n",
    "precision_macro_tfid=precision_score(ya_test_tfid,logistic_X_test_prediciton_macro_tfid,average='macro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_macro_tfid = recall_score(ya_test_tfid,logistic_X_test_prediciton_macro_tfid,average='macro')\n",
    "print(\"Macro_Score Precision: {:.4f}\".format(precision_macro_tfid))\n",
    "print(\"Macro_Score Recall: {:.4f}\".format(recall_macro_tfid))\n",
    "for i_tfid in range(4):\n",
    "    #f1_macro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_macro])\n",
    "    f1_macro_i_tfid = f1_score(ya_test_tfid[:,i_tfid],logistic_X_test_prediciton_macro_tfid[:,i_tfid])\n",
    "    print(f\"{header[i_tfid+2]} Macro_Score F1: {f1_macro_i_tfid:.4f}\")\n",
    "    \n",
    "print()    \n",
    "    \n",
    "\n",
    "#initialize GridSearchCV with scoring f1_micro:\n",
    "\n",
    "init_grid_search_micro_tfid=GridSearchCV(log_reg_tfid,params_tfid,cv=5,scoring='f1_micro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_micro:\n",
    "init_grid_search_micro_tfid.fit(X_train_matrix_tfid,ya_train_tfid)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_micro_score_tfid = init_grid_search_micro_tfid.score(X_test_matrix_tfid,ya_test_tfid) \n",
    "validation_results_best_score_micro_tfid=init_grid_search_micro_tfid.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Micro Validation Score F1: {:.4f}\".format(validation_results_best_score_micro_tfid))\n",
    "print(\"Micro Test Score F1: {:.4f}\".format(validation_micro_score_tfid))\n",
    "\n",
    "# Get the score from the GridSearchCV \"best score\" with Micro f1:\n",
    "#print(\"Micro_Score Validation F1: {:.4f}\".format(validation_micro_score))\n",
    "\n",
    "#predciting on X_test data with scoring f1_micro:\n",
    "logistic_X_test_prediciton_micro_tfid=init_grid_search_micro_tfid.predict(X_test_matrix_tfid)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as micro parameter:\n",
    "precision_micro_tfid=precision_score(ya_test_tfid,logistic_X_test_prediciton_micro_tfid,average='micro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_micro_tfid = recall_score(ya_test_tfid,logistic_X_test_prediciton_micro_tfid,average='micro')\n",
    "print(\"Micro_Score Precision: {:.4f}\".format(precision_micro_tfid))\n",
    "print(\"Micro_Score Recall: {:.4f}\".format(recall_micro_tfid))\n",
    "for i_tfid in range(4):\n",
    "    #f1_micro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_micro])\n",
    "    f1_micro_i_tfid = f1_score(ya_test_tfid[:,i_tfid],logistic_X_test_prediciton_micro_tfid[:,i_tfid])\n",
    "    print(f\"{header[i_tfid+2]} Micro_Score F1: {f1_micro_i_tfid:.4f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8e7b3f2-fa4c-4be7-983c-dea27967491b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lexicon features class declaration: Tech word Count,Onlie App,\n",
    "# Exclamation points and their count:\n",
    "class LexiconClassifier():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.exclamation_points = set()\n",
    "        self.online_apps_words=set()\n",
    "        self.technology_app_wrd=set()\n",
    "        self.food_delivery_app_wrd=set()\n",
    "        \n",
    "    def technology_wrd(self, file_path):\n",
    "        with open('./technology-words.txt',encoding='iso-8859-1') as iFile:\n",
    "            for row in iFile:\n",
    "                word=row.strip().lower()\n",
    "                self.technology_app_wrd.add(word)\n",
    "                #print(word)\n",
    "                \n",
    "    def fooddelivery_app(self, file_path):\n",
    "        with open('./food-delivery-words.txt',encoding='iso-8859-1') as iFile:\n",
    "            for row in iFile:\n",
    "                word=row.strip().lower()\n",
    "                self.food_delivery_app_wrd.add(word)\n",
    "    \n",
    "    def online_apps(self, file_path):\n",
    "        with open('./online-words.txt',encoding='iso-8859-1') as iFile:\n",
    "            for row in iFile:\n",
    "                word=row.strip().lower()\n",
    "                self.online_apps_words.add(word)\n",
    "               # print(row.strip())\n",
    "                \n",
    "    def load_exclamation_points(self, file_path):\n",
    "        with open('./Gold Standards DataSet_D_SA.csv',encoding='iso-8859-1') as iFile:\n",
    "            for row in iFile:\n",
    "                word=row.strip().lower()\n",
    "                self.exclamation_points.add(word)\n",
    "                #print(row.strip())\n",
    "\n",
    "    def predict_exclamation_points(self, sentence):\n",
    "        \"\"\"\n",
    "            Returns the number of exclamation points in a string.\n",
    "\n",
    "            Keyword arguments:\n",
    "            sentence -- string (e.g., \"This is great!!!\")\n",
    "\n",
    "            Returns:\n",
    "            num_exclamation_points -- an integer (e.g., 3)\n",
    "        \"\"\"\n",
    "        num_exclamation_points = 0\n",
    "        for char in sentence:\n",
    "            if char == '!':\n",
    "                num_exclamation_points += 1\n",
    "        return num_exclamation_points\n",
    "    \n",
    "   \n",
    "    \n",
    "    def predict_online_apps(self, sentence):\n",
    "            \n",
    "        \"\"\"\n",
    "        Returns True if specific online application words are found in a comment.\n",
    "\n",
    "        Keyword arguments:\n",
    "        sentence -- string (e.g., \"I ordered from ubereats and doordash today.\")\n",
    "\n",
    "        Returns:\n",
    "        count of online_apps_present -- 2 \n",
    "        \"\"\"\n",
    "        online_apps_count = sum(word in sentence.lower() for word in self.online_apps_words)\n",
    "        return online_apps_count\n",
    "    \n",
    "    def predict_fooddelivery_apps(self, sentence):\n",
    "            \n",
    "        \"\"\"\n",
    "        Returns True if specific online application words are found in a comment.\n",
    "\n",
    "        Keyword arguments:\n",
    "        sentence -- string (e.g., \"I ordered from ubereats and doordash today.\")\n",
    "\n",
    "        Returns:\n",
    "        count of online_apps_present -- 2 \n",
    "        \"\"\"\n",
    "        fooddelivery_apps_count = sum(word in sentence.lower() for word in self.food_delivery_app_wrd)\n",
    "        return fooddelivery_apps_count\n",
    "    \n",
    "    def predict_technology_app(self, sentence):\n",
    "            \n",
    "        \"\"\"\n",
    "        Returns True if specific online application words are found in a comment.\n",
    "\n",
    "        Keyword arguments:\n",
    "        sentence -- string (e.g., \"I ordered from ubereats and doordash today.\")\n",
    "\n",
    "        Returns:\n",
    "        count of online_apps_present -- 2 \n",
    "        \"\"\"\n",
    "        technology_apps_count = sum(word in sentence.lower() for word in self.technology_app_wrd)\n",
    "        return technology_apps_count\n",
    "\n",
    "# Create an instance of LexiconClassifier\n",
    "#classifier_instance = LexiconClassifier()\n",
    "\n",
    "# Call the technology_wrd method with the file path\n",
    "#classifier_instance.load_capital_words('./Gold Standards DataSet_D_SA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afdac016-3999-49e7-b6ee-fd2022b5f894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lexicon features labels for hstack: Food delivery word count, Technology word count,Onlie App word count, \n",
    "#Exclamation points and their count:\n",
    "# WRITE CODE HERE\n",
    "\n",
    "# Initailze to an empty list. This will be a list of li #  Initailze to an empty list. This will be a list of lists\n",
    "X_test_lexicon_features_em=[]\n",
    "X_train_lexicon_features_em=[]\n",
    "X_train_lexicon_features_twc=[]\n",
    "X_test_lexicon_features_twc=[]\n",
    "X_train_lexicon_features_ola=[]\n",
    "X_test_lexicon_features_ola=[]\n",
    "X_train_lexicon_features_fda=[]\n",
    "X_test_lexicon_features_fda=[]\n",
    "# Loop over X_txt_test\n",
    "#    for each string in X_txt_test (i.e., for each item in the list), pass it to LexiconClassifiers .count_pos_words() and count_neg_words method\n",
    "#    append a list with the counts to X_test_lexicon_features\n",
    "LexiconClassifier_v=LexiconClassifier()\n",
    "    \n",
    "#count of exclamation points:    \n",
    "for a in X_test:\n",
    "    num_exclamation_test_count=LexiconClassifier_v .predict_exclamation_points(a)\n",
    "    X_test_lexicon_features_em.append(num_exclamation_test_count)\n",
    "\n",
    "\n",
    "for b in X_train:\n",
    "    num_exclamation_train_count=LexiconClassifier_v .predict_exclamation_points(b)\n",
    "    X_train_lexicon_features_em.append(num_exclamation_train_count)\n",
    "    \n",
    "#count of technology words count:    \n",
    "for u in X_test:\n",
    "    num_tech_wrd_test_count=LexiconClassifier_v .predict_technology_app(u)\n",
    "    X_test_lexicon_features_twc.append(num_tech_wrd_test_count)\n",
    "\n",
    "\n",
    "for v in X_train:\n",
    "    num_tech_wrd_train_count=LexiconClassifier_v .predict_technology_app(v)\n",
    "    X_train_lexicon_features_twc.append(num_tech_wrd_train_count)\n",
    "\n",
    "\n",
    "#count of online app words count:    \n",
    "for e in X_test:\n",
    "    num_online_wrd_test_count=LexiconClassifier_v .predict_online_apps(e)\n",
    "    X_test_lexicon_features_ola.append(num_online_wrd_test_count)\n",
    "\n",
    "\n",
    "for f in X_train:\n",
    "    num_online_wrd_train_count=LexiconClassifier_v .predict_online_apps(f)\n",
    "    X_train_lexicon_features_ola.append(num_online_wrd_train_count)\n",
    "\n",
    "\n",
    "#count of fooddelivery app words count:    \n",
    "for g in X_test:\n",
    "    num_fooddel_wrd_test_count=LexiconClassifier_v .predict_fooddelivery_apps(g)\n",
    "    X_test_lexicon_features_fda.append(num_fooddel_wrd_test_count)\n",
    "\n",
    "\n",
    "for h in X_train:\n",
    "    num_fooddel_wrd_train_count=LexiconClassifier_v .predict_fooddelivery_apps(h)\n",
    "    X_train_lexicon_features_fda.append(num_fooddel_wrd_train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74c03cfc-6f58-4c8a-b857-a8eb01e0ef01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Validation Score F1- Exclamation Feature: 0.4115\n",
      "Macro Test Score F1- Exclamation Feature: 0.3990\n",
      "Macro_Score Precision-Exclamation Feature: 0.4113\n",
      "Macro_Score Recall-Exclamation Feature: 0.3926\n",
      "Gold Standards- Technology Macro_Score F1-Exclamation Feature: 0.8099\n",
      "Gold Standards- Ride Share Macro_Score F1-Exclamation Feature: 0.2069\n",
      "Gold Standards- Food Delivery Macro_Score F1-Exclamation Feature: 0.3548\n",
      "Gold Standards- Online Shopping Macro_Score F1-Exclamation Feature: 0.2243\n",
      "\n",
      "Micro Validation Score F1-Exclamation Feature: 0.5208\n",
      "Micro Test Score F1-Exclamation Feature: 0.4982\n",
      "Micro_Score Precision-Exclamation Feature: 0.5292\n",
      "Micro_Score Recall-Exclamation Feature: 0.4706\n",
      "Gold Standards- Technology Micro_Score F1-Exclamation Feature: 0.8151\n",
      "Gold Standards- Ride Share Micro_Score F1-Exclamation Feature: 0.1882\n",
      "Gold Standards- Food Delivery Micro_Score F1-Exclamation Feature: 0.3471\n",
      "Gold Standards- Online Shopping Micro_Score F1-Exclamation Feature: 0.1961\n"
     ]
    }
   ],
   "source": [
    "#modeling with count of exclamation marks ngram_range=(1,1) & LogisticRegression with CountVectorizer: \n",
    "\n",
    "#converting list to matrix for exclamation marks:\n",
    "vec_em=CountVectorizer(ngram_range=(1,1))\n",
    "X_train_matrix_em =vec_em.fit_transform(X_train) # This should be a matrix\n",
    "X_test_matrix_em=vec_em.transform(X_test)# This should be a matrix\n",
    "\n",
    "# Now we need to convert X_train_lexicon_features and X_test_lexicon_features to numpy arrays\n",
    "# \"hstack\" X_train_lexicon_features with X_train_w_lex\n",
    "# \"hstack\" X_test_lexicon_features with X_test_w_lex\n",
    "X_train_lexicon_farray_em=np.array(X_train_lexicon_features_em).reshape(-1, 1)\n",
    "X_test_lexicon_farray_em=np.array(X_test_lexicon_features_em).reshape(-1, 1)\n",
    "\n",
    "X_train_f_em_lex=hstack([X_train_matrix_em,X_train_lexicon_farray_em])\n",
    "X_test_f_em_lex=hstack([X_test_matrix_em,X_test_lexicon_farray_em])\n",
    "\n",
    "#converting list to array:\n",
    "ya_train_em=np.array(y_train)\n",
    "ya_test_em=np.array(y_test)\n",
    "#print(y_test.shape[1])\n",
    "\n",
    "#initializing logisticregression:\n",
    "log_reg_f_em=MultiOutputClassifier(LogisticRegression(random_state=42,solver='lbfgs', max_iter=2000))\n",
    "\n",
    "#params with c values:\n",
    "params_em= {\"estimator__C\": [0.0001, 0.001, 0.01, 0.1, 1, 10,100]}\n",
    "\n",
    "#initialize GridSearchCV with scoring f1_macro:\n",
    "\n",
    "init_grid_search_macro_f_em=GridSearchCV(log_reg_f_em,params_em,cv=5,scoring='f1_macro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_macro:\n",
    "init_grid_search_macro_f_em.fit(X_train_f_em_lex,ya_train_em)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_macro_score_f_em = init_grid_search_macro_f_em.score(X_test_f_em_lex,ya_test_em) \n",
    "validation_results_best_score_f_em=init_grid_search_macro_f_em.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Macro Validation Score F1- Exclamation Feature: {:.4f}\".format(validation_results_best_score_f_em))\n",
    "print(\"Macro Test Score F1- Exclamation Feature: {:.4f}\".format(validation_macro_score_f_em))\n",
    "\n",
    "#predciting on X_test data with scoring f1_macro:\n",
    "logistic_X_test_prediciton_macro_f_em=init_grid_search_macro_f_em.predict(X_test_f_em_lex)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as macro parameter:\n",
    "precision_macro_f_em=precision_score(ya_test_em,logistic_X_test_prediciton_macro_f_em,average='macro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_macro_f_em = recall_score(ya_test_em,logistic_X_test_prediciton_macro_f_em,average='macro')\n",
    "print(\"Macro_Score Precision-Exclamation Feature: {:.4f}\".format(precision_macro_f_em))\n",
    "print(\"Macro_Score Recall-Exclamation Feature: {:.4f}\".format(recall_macro_f_em))\n",
    "for i_ma in range(4):\n",
    "    #f1_macro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_macro])\n",
    "    f1_macro_f_em_i_ma = f1_score(ya_test_em[:,i_ma],logistic_X_test_prediciton_macro_f_em[:,i_ma])\n",
    "    print(f\"{header[i_ma+2]} Macro_Score F1-Exclamation Feature: {f1_macro_f_em_i_ma:.4f}\")\n",
    "    \n",
    "print()    \n",
    "    \n",
    "\n",
    "#initialize GridSearchCV with scoring f1_micro:\n",
    "\n",
    "init_grid_search_micro_f_em=GridSearchCV(log_reg_f_em,params_em,cv=5,scoring='f1_micro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_micro:\n",
    "init_grid_search_micro_f_em.fit(X_train_f_em_lex,ya_train_em)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_micro_score_f_em = init_grid_search_micro_f_em.score(X_test_f_em_lex,ya_test_em) \n",
    "validation_results_best_score_micro_f_em=init_grid_search_micro_f_em.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Micro Validation Score F1-Exclamation Feature: {:.4f}\".format(validation_results_best_score_micro_f_em))\n",
    "print(\"Micro Test Score F1-Exclamation Feature: {:.4f}\".format(validation_micro_score_f_em))\n",
    "\n",
    "# Get the score from the GridSearchCV \"best score\" with Micro f1:\n",
    "#print(\"Micro_Score Validation F1: {:.4f}\".format(validation_micro_score))\n",
    "\n",
    "#predciting on X_test data with scoring f1_micro:\n",
    "logistic_X_test_prediciton_micro_f_em=init_grid_search_micro_f_em.predict(X_test_f_em_lex)\n",
    "#print(logistic_X_test_prediciton_micro_f_em)\n",
    "# Calculating precision, recall and f1 Scores with average as micro parameter:\n",
    "precision_micro_f_em=precision_score(ya_test_em,logistic_X_test_prediciton_micro_f_em,average='micro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_micro_f_em = recall_score(ya_test_em,logistic_X_test_prediciton_micro_f_em,average='micro')\n",
    "print(\"Micro_Score Precision-Exclamation Feature: {:.4f}\".format(precision_micro_f_em))\n",
    "print(\"Micro_Score Recall-Exclamation Feature: {:.4f}\".format(recall_micro_f_em))\n",
    "for i_mi in range(4):\n",
    "    #f1_micro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_micro])\n",
    "    f1_micro_f_em_i_mi = f1_score(ya_test_em[:,i_mi],logistic_X_test_prediciton_micro_f_em[:,i_mi])\n",
    "    print(f\"{header[i_mi+2]} Micro_Score F1-Exclamation Feature: {f1_micro_f_em_i_mi:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c0a66d7-7e9f-4949-8e22-224b4a5807cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Validation Score F1- Tech word count Feature: 0.3796\n",
      "Macro Test Score F1- Tech word count Feature: 0.3429\n",
      "Macro_Score Precision-Tech word count Feature: 0.3956\n",
      "Macro_Score Recall-Tech word count Feature: 0.3240\n",
      "Gold Standards- Technology Macro_Score F1-Tech word count Feature: 0.8230\n",
      "Gold Standards- Ride Share Macro_Score F1-Tech word count Feature: 0.1176\n",
      "Gold Standards- Food Delivery Macro_Score F1-Tech word count Feature: 0.2752\n",
      "Gold Standards- Online Shopping Macro_Score F1-Tech word count Feature: 0.1556\n",
      "\n",
      "Micro Validation Score F1-Tech word count Feature: 0.5212\n",
      "Micro Test Score F1-Tech word count Feature: 0.5010\n",
      "Micro_Score Precision-Tech word count Feature: 0.6089\n",
      "Micro_Score Recall-Tech word count Feature: 0.4256\n",
      "Gold Standards- Technology Micro_Score F1-Tech word count Feature: 0.8197\n",
      "Gold Standards- Ride Share Micro_Score F1-Tech word count Feature: 0.1818\n",
      "Gold Standards- Food Delivery Micro_Score F1-Tech word count Feature: 0.2353\n",
      "Gold Standards- Online Shopping Micro_Score F1-Tech word count Feature: 0.1266\n"
     ]
    }
   ],
   "source": [
    "#modeling with count of technology word count ngram_range=(1,2) & LogisticRegression with CountVectorizer: \n",
    "\n",
    "#converting list to matrix for technology word count:\n",
    "vec_twc=CountVectorizer(ngram_range=(1,2))\n",
    "X_train_matrix_twc =vec_twc.fit_transform(X_train) # This should be a matrix\n",
    "X_test_matrix_twc=vec_twc.transform(X_test)# This should be a matrix\n",
    "\n",
    "# Now we need to convert X_train_lexicon_features and X_test_lexicon_features to numpy arrays\n",
    "# \"hstack\" X_train_lexicon_features with X_train_w_lex\n",
    "# \"hstack\" X_test_lexicon_features with X_test_w_lex\n",
    "X_train_lexicon_farray_twc=np.array(X_train_lexicon_features_twc).reshape(-1, 1)\n",
    "X_test_lexicon_farray_twc=np.array(X_test_lexicon_features_twc).reshape(-1, 1)\n",
    "\n",
    "X_train_f_twc_lex=hstack([X_train_matrix_twc,X_train_lexicon_farray_twc])\n",
    "X_test_f_twc_lex=hstack([X_test_matrix_twc,X_test_lexicon_farray_twc])\n",
    "\n",
    "#converting list to array:\n",
    "ya_train_twc=np.array(y_train)\n",
    "ya_test_twc=np.array(y_test)\n",
    "#print(y_test.shape[1])\n",
    "\n",
    "#initializing logisticregression:\n",
    "log_reg_f_twc=MultiOutputClassifier(LogisticRegression(random_state=42,solver='lbfgs', max_iter=2000))\n",
    "\n",
    "#params with c values:\n",
    "params_twc= {\"estimator__C\": [0.0001, 0.001, 0.01, 0.1, 1, 10,100]}\n",
    "\n",
    "#initialize GridSearchCV with scoring f1_macro:\n",
    "\n",
    "init_grid_search_macro_f_twc=GridSearchCV(log_reg_f_twc,params_twc,cv=5,scoring='f1_macro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_macro:\n",
    "init_grid_search_macro_f_twc.fit(X_train_f_twc_lex,ya_train_twc)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_macro_score_f_twc = init_grid_search_macro_f_twc.score(X_test_f_twc_lex,ya_test_twc) \n",
    "validation_results_best_score_f_twc=init_grid_search_macro_f_twc.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Macro Validation Score F1- Tech word count Feature: {:.4f}\".format(validation_results_best_score_f_twc))\n",
    "print(\"Macro Test Score F1- Tech word count Feature: {:.4f}\".format(validation_macro_score_f_twc))\n",
    "\n",
    "#predciting on X_test data with scoring f1_macro:\n",
    "logistic_X_test_prediciton_macro_f_twc=init_grid_search_macro_f_twc.predict(X_test_f_twc_lex)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as macro parameter:\n",
    "precision_macro_f_twc=precision_score(ya_test_twc,logistic_X_test_prediciton_macro_f_twc,average='macro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_macro_f_twc = recall_score(ya_test_twc,logistic_X_test_prediciton_macro_f_twc,average='macro')\n",
    "print(\"Macro_Score Precision-Tech word count Feature: {:.4f}\".format(precision_macro_f_twc))\n",
    "print(\"Macro_Score Recall-Tech word count Feature: {:.4f}\".format(recall_macro_f_twc))\n",
    "for i_twc_mac in range(4):\n",
    "    #f1_macro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_macro])\n",
    "    f1_macro_f_twc_i_twc = f1_score(ya_test_twc[:,i_twc_mac],logistic_X_test_prediciton_macro_f_twc[:,i_twc_mac])\n",
    "    print(f\"{header[i_twc_mac+2]} Macro_Score F1-Tech word count Feature: {f1_macro_f_twc_i_twc:.4f}\")\n",
    "    \n",
    "print()    \n",
    "    \n",
    "\n",
    "#initialize GridSearchCV with scoring f1_micro:\n",
    "\n",
    "init_grid_search_micro_f_twc=GridSearchCV(log_reg_f_twc,params_twc,cv=5,scoring='f1_micro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_micro:\n",
    "init_grid_search_micro_f_twc.fit(X_train_f_twc_lex,ya_train_twc)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_micro_score_f_twc = init_grid_search_micro_f_twc.score(X_test_f_twc_lex,ya_test_twc) \n",
    "validation_results_best_score_micro_f_twc=init_grid_search_micro_f_twc.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Micro Validation Score F1-Tech word count Feature: {:.4f}\".format(validation_results_best_score_micro_f_twc))\n",
    "print(\"Micro Test Score F1-Tech word count Feature: {:.4f}\".format(validation_micro_score_f_twc))\n",
    "\n",
    "# Get the score from the GridSearchCV \"best score\" with Micro f1:\n",
    "#print(\"Micro_Score Validation F1: {:.4f}\".format(validation_micro_score))\n",
    "\n",
    "#predciting on X_test data with scoring f1_micro:\n",
    "logistic_X_test_prediciton_micro_f_twc=init_grid_search_micro_f_twc.predict(X_test_f_twc_lex)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as micro parameter:\n",
    "precision_micro_f_twc=precision_score(ya_test_twc,logistic_X_test_prediciton_micro_f_twc,average='micro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_micro_f_twc = recall_score(ya_test_twc,logistic_X_test_prediciton_micro_f_twc,average='micro')\n",
    "print(\"Micro_Score Precision-Tech word count Feature: {:.4f}\".format(precision_micro_f_twc))\n",
    "print(\"Micro_Score Recall-Tech word count Feature: {:.4f}\".format(recall_micro_f_twc))\n",
    "for i_twc_mic in range(4):\n",
    "    #f1_micro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_micro])\n",
    "    f1_micro_f_twc_i_twc_mic = f1_score(ya_test_twc[:,i_twc_mic],logistic_X_test_prediciton_micro_f_twc[:,i_twc_mic])\n",
    "    print(f\"{header[i_twc_mic+2]} Micro_Score F1-Tech word count Feature: {f1_micro_f_twc_i_twc_mic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "064a01e0-5c55-4ea1-a8b5-ba4893205617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Validation Score F1- online app word count Feature: 0.2504\n",
      "Macro Test Score F1- online app word count Feature: 0.2398\n",
      "Macro_Score Precision-online app word count Feature: 0.4013\n",
      "Macro_Score Recall-online app word count Feature: 0.2634\n",
      "Gold Standards- Technology Macro_Score F1-online app word count Feature: 0.7535\n",
      "Gold Standards- Ride Share Macro_Score F1-online app word count Feature: 0.0741\n",
      "Gold Standards- Food Delivery Macro_Score F1-online app word count Feature: 0.0460\n",
      "Gold Standards- Online Shopping Macro_Score F1-online app word count Feature: 0.0857\n",
      "\n",
      "Micro Validation Score F1-online app word count Feature: 0.4967\n",
      "Micro Test Score F1-online app word count Feature: 0.4807\n",
      "Micro_Score Precision-online app word count Feature: 0.5842\n",
      "Micro_Score Recall-online app word count Feature: 0.4083\n",
      "Gold Standards- Technology Micro_Score F1-online app word count Feature: 0.7331\n",
      "Gold Standards- Ride Share Micro_Score F1-online app word count Feature: 0.0385\n",
      "Gold Standards- Food Delivery Micro_Score F1-online app word count Feature: 0.0286\n",
      "Gold Standards- Online Shopping Micro_Score F1-online app word count Feature: 0.0690\n"
     ]
    }
   ],
   "source": [
    "#modeling with count of online app word count ngram_range=(2,3) & LogisticRegression with CountVectorizer: \n",
    "\n",
    "#converting list to matrix for technology word count:\n",
    "vec_olp=CountVectorizer(ngram_range=(2,3))\n",
    "X_train_matrix_olp =vec_olp.fit_transform(X_train) # This should be a matrix\n",
    "X_test_matrix_olp=vec_olp.transform(X_test)# This should be a matrix\n",
    "\n",
    "# Now we need to convert X_train_lexicon_features and X_test_lexicon_features to numpy arrays\n",
    "# \"hstack\" X_train_lexicon_features with X_train_w_lex\n",
    "# \"hstack\" X_test_lexicon_features with X_test_w_lex\n",
    "X_train_lexicon_farray_olp=np.array(X_train_lexicon_features_ola).reshape(-1, 1)\n",
    "X_test_lexicon_farray_olp=np.array(X_test_lexicon_features_ola).reshape(-1, 1)\n",
    "\n",
    "X_train_f_olp_lex=hstack([X_train_matrix_olp,X_train_lexicon_farray_olp])\n",
    "X_test_f_olp_lex=hstack([X_test_matrix_olp,X_test_lexicon_farray_olp])\n",
    "\n",
    "#converting list to array:\n",
    "ya_train_olp=np.array(y_train)\n",
    "ya_test_olp=np.array(y_test)\n",
    "#print(y_test.shape[1])\n",
    "\n",
    "#initializing logisticregression:\n",
    "log_reg_f_olp=MultiOutputClassifier(LogisticRegression(random_state=42,solver='lbfgs', max_iter=2000))\n",
    "\n",
    "#params with c values:\n",
    "params_olp= {\"estimator__C\": [0.0001, 0.001, 0.01, 0.1, 1, 10,100]}\n",
    "\n",
    "#initialize GridSearchCV with scoring f1_macro:\n",
    "\n",
    "init_grid_search_macro_f_olp=GridSearchCV(log_reg_f_olp,params_olp,cv=5,scoring='f1_macro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_macro:\n",
    "init_grid_search_macro_f_olp.fit(X_train_f_olp_lex,ya_train_olp)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_macro_score_f_olp = init_grid_search_macro_f_olp.score(X_test_f_olp_lex,ya_test_olp) \n",
    "validation_results_best_score_f_olp=init_grid_search_macro_f_olp.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Macro Validation Score F1- online app word count Feature: {:.4f}\".format(validation_results_best_score_f_olp))\n",
    "print(\"Macro Test Score F1- online app word count Feature: {:.4f}\".format(validation_macro_score_f_olp))\n",
    "\n",
    "#predciting on X_test data with scoring f1_macro:\n",
    "logistic_X_test_prediciton_macro_f_olp=init_grid_search_macro_f_olp.predict(X_test_f_olp_lex)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as macro parameter:\n",
    "precision_macro_f_olp=precision_score(ya_test_olp,logistic_X_test_prediciton_macro_f_olp,average='macro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_macro_f_olp = recall_score(ya_test_olp,logistic_X_test_prediciton_macro_f_olp,average='macro')\n",
    "print(\"Macro_Score Precision-online app word count Feature: {:.4f}\".format(precision_macro_f_olp))\n",
    "print(\"Macro_Score Recall-online app word count Feature: {:.4f}\".format(recall_macro_f_olp))\n",
    "for i_olp_mac in range(4):\n",
    "    #f1_macro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_macro])\n",
    "    f1_macro_f_olp_i_olp = f1_score(ya_test_olp[:,i_olp_mac],logistic_X_test_prediciton_macro_f_olp[:,i_olp_mac])\n",
    "    print(f\"{header[i_olp_mac+2]} Macro_Score F1-online app word count Feature: {f1_macro_f_olp_i_olp:.4f}\")\n",
    "    \n",
    "print()    \n",
    "    \n",
    "\n",
    "#initialize GridSearchCV with scoring f1_micro:\n",
    "\n",
    "init_grid_search_micro_f_olp=GridSearchCV(log_reg_f_olp,params_olp,cv=5,scoring='f1_micro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_micro:\n",
    "init_grid_search_micro_f_olp.fit(X_train_f_olp_lex,ya_train_olp)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_micro_score_f_olp = init_grid_search_micro_f_olp.score(X_test_f_olp_lex,ya_test_olp) \n",
    "validation_results_best_score_micro_f_olp=init_grid_search_micro_f_olp.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Micro Validation Score F1-online app word count Feature: {:.4f}\".format(validation_results_best_score_micro_f_olp))\n",
    "print(\"Micro Test Score F1-online app word count Feature: {:.4f}\".format(validation_micro_score_f_olp))\n",
    "\n",
    "# Get the score from the GridSearchCV \"best score\" with Micro f1:\n",
    "#print(\"Micro_Score Validation F1: {:.4f}\".format(validation_micro_score))\n",
    "\n",
    "#predciting on X_test data with scoring f1_micro:\n",
    "logistic_X_test_prediciton_micro_f_olp=init_grid_search_micro_f_olp.predict(X_test_f_olp_lex)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as micro parameter:\n",
    "precision_micro_f_olp=precision_score(ya_test_olp,logistic_X_test_prediciton_micro_f_olp,average='micro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_micro_f_olp = recall_score(ya_test_olp,logistic_X_test_prediciton_micro_f_olp,average='micro')\n",
    "print(\"Micro_Score Precision-online app word count Feature: {:.4f}\".format(precision_micro_f_olp))\n",
    "print(\"Micro_Score Recall-online app word count Feature: {:.4f}\".format(recall_micro_f_olp))\n",
    "for i_olp_mic in range(4):\n",
    "    #f1_micro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_micro])\n",
    "    f1_micro_f_olp_i_olp_mic = f1_score(ya_test_olp[:,i_olp_mic],logistic_X_test_prediciton_micro_f_olp[:,i_olp_mic])\n",
    "    print(f\"{header[i_olp_mic+2]} Micro_Score F1-online app word count Feature: {f1_micro_f_olp_i_olp_mic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1f1b585-ab80-4f98-90ca-4a2bac11d1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Validation Score F1- Food delivery app word count Feature: 0.3429\n",
      "Macro Test Score F1- Food delivery app word count Feature: 0.3216\n",
      "Macro_Score Precision-Food delivery app word count Feature: 0.4368\n",
      "Macro_Score Recall-Food delivery app word count Feature: 0.2927\n",
      "Gold Standards- Food Delivery Macro_Score F1-Food delivery app word count Feature: 0.1429\n",
      "\n",
      "Micro Validation Score F1-Food delivery app word count Feature: 0.5131\n",
      "Micro Test Score F1-Food delivery app word count Feature: 0.4820\n",
      "Micro_Score Precision-Food delivery app word count Feature: 0.6196\n",
      "Micro_Score Recall-Food delivery app word count Feature: 0.3945\n",
      "Gold Standards- Food Delivery Micro_Score F1-Food delivery app word count Feature: 0.1443\n"
     ]
    }
   ],
   "source": [
    "#modeling with count of food delivery app word count ngram_range=(1,4) & \n",
    "#LogisticRegression with CountVectorizer: \n",
    "\n",
    "#converting list to matrix for technology word count:\n",
    "vec_fda=CountVectorizer(ngram_range=(1,4))\n",
    "X_train_matrix_fda =vec_fda.fit_transform(X_train) # This should be a matrix\n",
    "X_test_matrix_fda=vec_fda.transform(X_test)# This should be a matrix\n",
    "\n",
    "# Now we need to convert X_train_lexicon_features and X_test_lexicon_features to numpy arrays\n",
    "# \"hstack\" X_train_lexicon_features with X_train_w_lex\n",
    "# \"hstack\" X_test_lexicon_features with X_test_w_lex\n",
    "X_train_lexicon_farray_fda=np.array(X_train_lexicon_features_fda).reshape(-1, 1)\n",
    "X_test_lexicon_farray_fda=np.array(X_test_lexicon_features_fda).reshape(-1, 1)\n",
    "\n",
    "X_train_f_fda_lex=hstack([X_train_matrix_fda,X_train_lexicon_farray_fda])\n",
    "X_test_f_fda_lex=hstack([X_test_matrix_fda,X_test_lexicon_farray_fda])\n",
    "\n",
    "#converting list to array:\n",
    "ya_train_fda=np.array(y_train)\n",
    "ya_test_fda=np.array(y_test)\n",
    "#print(y_test.shape[1])\n",
    "\n",
    "#initializing logisticregression:\n",
    "log_reg_f_fda=MultiOutputClassifier(LogisticRegression(random_state=42,solver='lbfgs', max_iter=2000))\n",
    "\n",
    "#params with c values:\n",
    "params_fda= {\"estimator__C\": [0.0001, 0.001, 0.01, 0.1, 1, 10,100]}\n",
    "\n",
    "#initialize GridSearchCV with scoring f1_macro:\n",
    "\n",
    "init_grid_search_macro_f_fda=GridSearchCV(log_reg_f_fda,params_fda,cv=5,scoring='f1_macro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_macro:\n",
    "init_grid_search_macro_f_fda.fit(X_train_f_fda_lex,ya_train_fda)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_macro_score_f_fda = init_grid_search_macro_f_fda.score(X_test_f_fda_lex,ya_test_fda) \n",
    "validation_results_best_score_f_fda=init_grid_search_macro_f_fda.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Macro Validation Score F1- Food delivery app word count Feature: {:.4f}\".format(validation_results_best_score_f_fda))\n",
    "print(\"Macro Test Score F1- Food delivery app word count Feature: {:.4f}\".format(validation_macro_score_f_fda))\n",
    "\n",
    "#predciting on X_test data with scoring f1_macro:\n",
    "logistic_X_test_prediciton_macro_f_fda=init_grid_search_macro_f_fda.predict(X_test_f_fda_lex)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as macro parameter:\n",
    "precision_macro_f_fda=precision_score(ya_test_fda,logistic_X_test_prediciton_macro_f_fda,average='macro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_macro_f_fda = recall_score(ya_test_fda,logistic_X_test_prediciton_macro_f_fda,average='macro')\n",
    "print(\"Macro_Score Precision-Food delivery app word count Feature: {:.4f}\".format(precision_macro_f_fda))\n",
    "print(\"Macro_Score Recall-Food delivery app word count Feature: {:.4f}\".format(recall_macro_f_fda))\n",
    "#for i_fda_mac in range(4):\n",
    "    #f1_macro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_macro])\n",
    "i_fda_mac=2\n",
    "f1_macro_f_fda_i_fda = f1_score(ya_test_fda[:,i_fda_mac],logistic_X_test_prediciton_macro_f_fda[:,i_fda_mac])\n",
    "print(f\"{header[i_fda_mac+2]} Macro_Score F1-Food delivery app word count Feature: {f1_macro_f_fda_i_fda:.4f}\")\n",
    "    \n",
    "print()    \n",
    "    \n",
    "\n",
    "#initialize GridSearchCV with scoring f1_micro:\n",
    "\n",
    "init_grid_search_micro_f_fda=GridSearchCV(log_reg_f_fda,params_fda,cv=5,scoring='f1_micro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_micro:\n",
    "init_grid_search_micro_f_fda.fit(X_train_f_fda_lex,ya_train_fda)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_micro_score_f_fda = init_grid_search_micro_f_fda.score(X_test_f_fda_lex,ya_test_fda) \n",
    "validation_results_best_score_micro_f_fda=init_grid_search_micro_f_fda.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Micro Validation Score F1-Food delivery app word count Feature: {:.4f}\".format(validation_results_best_score_micro_f_fda))\n",
    "print(\"Micro Test Score F1-Food delivery app word count Feature: {:.4f}\".format(validation_micro_score_f_fda))\n",
    "\n",
    "# Get the score from the GridSearchCV \"best score\" with Micro f1:\n",
    "#print(\"Micro_Score Validation F1: {:.4f}\".format(validation_micro_score))\n",
    "\n",
    "#predciting on X_test data with scoring f1_micro:\n",
    "logistic_X_test_prediciton_micro_f_fda=init_grid_search_micro_f_fda.predict(X_test_f_fda_lex)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as micro parameter:\n",
    "precision_micro_f_fda=precision_score(ya_test_fda,logistic_X_test_prediciton_micro_f_fda,average='micro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_micro_f_fda = recall_score(ya_test_fda,logistic_X_test_prediciton_micro_f_fda,average='micro')\n",
    "print(\"Micro_Score Precision-Food delivery app word count Feature: {:.4f}\".format(precision_micro_f_fda))\n",
    "print(\"Micro_Score Recall-Food delivery app word count Feature: {:.4f}\".format(recall_micro_f_fda))\n",
    "#for i_fda_mic in range(3):\n",
    "    #f1_micro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_micro])\n",
    "i_fda_mic=2\n",
    "f1_micro_f_fda_i_fda_mic = f1_score(ya_test_fda[:,i_fda_mic],logistic_X_test_prediciton_micro_f_fda[:,i_fda_mic])\n",
    "print(f\"{header[i_fda_mic+2]} Micro_Score F1-Food delivery app word count Feature: {f1_micro_f_fda_i_fda_mic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "436ba061-5186-413f-97ee-78ecb1e839b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Validation Score F1- Food delivery app word count Feature: 0.2109\n",
      "Macro Test Score F1- Food delivery app word count Feature: 0.2498\n",
      "Macro_Score Precision-Food delivery app word count Feature: 0.4631\n",
      "Macro_Score Recall-Food delivery app word count Feature: 0.2622\n",
      "Gold Standards- Food Delivery Macro_Score F1-Food delivery app word count Feature: 0.0779\n",
      "\n",
      "Micro Validation Score F1-Food delivery app word count Feature: 0.4976\n",
      "Micro Test Score F1-Food delivery app word count Feature: 0.4903\n",
      "Micro_Score Precision-Food delivery app word count Feature: 0.6477\n",
      "Micro_Score Recall-Food delivery app word count Feature: 0.3945\n",
      "Gold Standards- Food Delivery Micro_Score F1-Food delivery app word count Feature: 0.0779\n"
     ]
    }
   ],
   "source": [
    "#modeling with count of food delivery app word count ngram_range=(1,4) & \n",
    "#LogisticRegression with TfidfVectorizer: \n",
    "\n",
    "#converting list to matrix for technology word count:\n",
    "vec_fda_tfid=TfidfVectorizer(ngram_range=(1,4))\n",
    "X_train_matrix_fda_tfid =vec_fda_tfid.fit_transform(X_train) # This should be a matrix\n",
    "X_test_matrix_fda_tfid=vec_fda_tfid.transform(X_test)# This should be a matrix\n",
    "\n",
    "# Now we need to convert X_train_lexicon_features and X_test_lexicon_features to numpy arrays\n",
    "# \"hstack\" X_train_lexicon_features with X_train_w_lex\n",
    "# \"hstack\" X_test_lexicon_features with X_test_w_lex\n",
    "X_train_lexicon_farray_fda_tfid=np.array(X_train_lexicon_features_fda).reshape(-1, 1)\n",
    "X_test_lexicon_farray_fda_tfid=np.array(X_test_lexicon_features_fda).reshape(-1, 1)\n",
    "\n",
    "X_train_f_fda_lex_tfid=hstack([X_train_matrix_fda_tfid,X_train_lexicon_farray_fda_tfid])\n",
    "X_test_f_fda_lex_tfid=hstack([X_test_matrix_fda_tfid,X_test_lexicon_farray_fda_tfid])\n",
    "\n",
    "#converting list to array:\n",
    "ya_train_fda_tfid=np.array(y_train)\n",
    "ya_test_fda_tfid=np.array(y_test)\n",
    "#print(y_test.shape[1])\n",
    "\n",
    "#initializing logisticregression:\n",
    "log_reg_f_fda_tfid=MultiOutputClassifier(LogisticRegression(random_state=42,solver='lbfgs', max_iter=2000))\n",
    "\n",
    "#params with c values:\n",
    "params_fda_tfid= {\"estimator__C\": [0.0001, 0.001, 0.01, 0.1, 1, 10,100]}\n",
    "\n",
    "#initialize GridSearchCV with scoring f1_macro:\n",
    "\n",
    "init_grid_search_macro_f_fda_tfid=GridSearchCV(log_reg_f_fda_tfid,params_fda_tfid,cv=5,scoring='f1_macro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_macro:\n",
    "init_grid_search_macro_f_fda_tfid.fit(X_train_f_fda_lex_tfid,ya_train_fda_tfid)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_macro_score_f_fda_tfid = init_grid_search_macro_f_fda_tfid.score(X_test_f_fda_lex_tfid,ya_test_fda_tfid) \n",
    "validation_results_best_score_f_fda_tfid=init_grid_search_macro_f_fda_tfid.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Macro Validation Score F1- Food delivery app word count Feature: {:.4f}\".format(validation_results_best_score_f_fda_tfid))\n",
    "print(\"Macro Test Score F1- Food delivery app word count Feature: {:.4f}\".format(validation_macro_score_f_fda_tfid))\n",
    "\n",
    "#predciting on X_test data with scoring f1_macro:\n",
    "logistic_X_test_prediciton_macro_f_fda_tfid=init_grid_search_macro_f_fda_tfid.predict(X_test_f_fda_lex_tfid)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as macro parameter:\n",
    "precision_macro_f_fda_tfid=precision_score(ya_test_fda_tfid,logistic_X_test_prediciton_macro_f_fda_tfid,average='macro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_macro_f_fda_tfid = recall_score(ya_test_fda_tfid,logistic_X_test_prediciton_macro_f_fda_tfid,average='macro')\n",
    "print(\"Macro_Score Precision-Food delivery app word count Feature: {:.4f}\".format(precision_macro_f_fda_tfid))\n",
    "print(\"Macro_Score Recall-Food delivery app word count Feature: {:.4f}\".format(recall_macro_f_fda_tfid))\n",
    "#for i_fda_mac in range(4):\n",
    "    #f1_macro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_macro])\n",
    "i_fda_mac_tfid=2\n",
    "f1_macro_f_fda_i_fda_tfid = f1_score(ya_test_fda_tfid[:,i_fda_mac_tfid],logistic_X_test_prediciton_macro_f_fda_tfid[:,i_fda_mac_tfid])\n",
    "print(f\"{header[i_fda_mac_tfid+2]} Macro_Score F1-Food delivery app word count Feature: {f1_macro_f_fda_i_fda_tfid:.4f}\")\n",
    "    \n",
    "print()    \n",
    "    \n",
    "\n",
    "#initialize GridSearchCV with scoring f1_micro:\n",
    "\n",
    "init_grid_search_micro_f_fda_tfid=GridSearchCV(log_reg_f_fda_tfid,params_fda_tfid,cv=5,scoring='f1_micro')\n",
    "\n",
    "# Fit the model on X_train with scoring f1_micro:\n",
    "init_grid_search_micro_f_fda_tfid.fit(X_train_f_fda_lex_tfid,ya_train_fda_tfid)\n",
    "\n",
    "#Validation Score with scoring f1_macro:\n",
    "validation_micro_score_f_fda_tfid = init_grid_search_micro_f_fda_tfid.score(X_test_f_fda_lex_tfid,ya_test_fda_tfid) \n",
    "validation_results_best_score_micro_f_fda_tfid=init_grid_search_micro_f_fda_tfid.best_score_\n",
    "# Get the score from the GridSearchCV \"best score\" with Macro f1:\n",
    "print(\"Micro Validation Score F1-Food delivery app word count Feature: {:.4f}\".format(validation_results_best_score_micro_f_fda_tfid))\n",
    "print(\"Micro Test Score F1-Food delivery app word count Feature: {:.4f}\".format(validation_micro_score_f_fda_tfid))\n",
    "\n",
    "# Get the score from the GridSearchCV \"best score\" with Micro f1:\n",
    "#print(\"Micro_Score Validation F1: {:.4f}\".format(validation_micro_score))\n",
    "\n",
    "#predciting on X_test data with scoring f1_micro:\n",
    "logistic_X_test_prediciton_micro_f_fda_tfid=init_grid_search_micro_f_fda_tfid.predict(X_test_f_fda_lex_tfid)\n",
    "\n",
    "# Calculating precision, recall and f1 Scores with average as micro parameter:\n",
    "precision_micro_f_fda_tfid=precision_score(ya_test_fda_tfid,logistic_X_test_prediciton_micro_f_fda_tfid,average='micro')  # Get scores using logistic_X_test_prediciton and y_test with the precision_score method\n",
    "recall_micro_f_fda_tfid = recall_score(ya_test_fda_tfid,logistic_X_test_prediciton_micro_f_fda_tfid,average='micro')\n",
    "print(\"Micro_Score Precision-Food delivery app word count Feature: {:.4f}\".format(precision_micro_f_fda_tfid))\n",
    "print(\"Micro_Score Recall-Food delivery app word count Feature: {:.4f}\".format(recall_micro_f_fda_tfid))\n",
    "#for i_fda_mic in range(3):\n",
    "    #f1_micro_i = f1_score([item[i] for item in y_test], [item[i] for item in logistic_X_test_prediciton_micro])\n",
    "i_fda_mic_tfid=2\n",
    "f1_micro_f_fda_i_fda_mic_tfid = f1_score(ya_test_fda_tfid[:,i_fda_mic_tfid],logistic_X_test_prediciton_micro_f_fda_tfid[:,i_fda_mic_tfid])\n",
    "print(f\"{header[i_fda_mic_tfid+2]} Micro_Score F1-Food delivery app word count Feature: {f1_micro_f_fda_i_fda_mic_tfid:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff304612-f047-4633-a558-4b48b5fb790e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: I think arts, culture, and science should be subsidized as it often appears that the free market doesn't grow those areas effectively and authentically.  But considering how cheap modern technology has made some things, such as making movies and tv shows, it may not be as necessary.\n",
      "['Gold Standards- Technology', 'Gold Standards- Ride Share', 'Gold Standards- Food Delivery', 'Gold Standards- Online Shopping']\n",
      "Ground-Truth Class: [0, 0, 0, 0]\n",
      "Lexicon Exclamation Model Prediction(micro f1): [1 0 1 0]\n",
      "Lexicon Exclamation Model Prediction(macro f1): [1 0 1 0]\n",
      "Lexicon Technology Word Count Model Prediction(macro f1): [1 0 0 1]\n",
      "Lexicon Technology Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(macro f1): [1 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(macro f1): [1 0 0 0]\n",
      "\n",
      "Tweet: If you wish to stick with iPhone, the iPhone 6S is still currently supported with iOS 15. You can get one used for about $75 on eBay and maybe even cheaper on a local marketplace app\n",
      "['Gold Standards- Technology', 'Gold Standards- Ride Share', 'Gold Standards- Food Delivery', 'Gold Standards- Online Shopping']\n",
      "Ground-Truth Class: [1, 0, 0, 1]\n",
      "Lexicon Exclamation Model Prediction(micro f1): [0 1 1 0]\n",
      "Lexicon Exclamation Model Prediction(macro f1): [0 1 1 0]\n",
      "Lexicon Technology Word Count Model Prediction(macro f1): [0 0 1 0]\n",
      "Lexicon Technology Word Count Model Prediction(micro f1): [1 0 1 0]\n",
      "Lexicon Online App Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(macro f1): [1 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(micro f1): [1 0 1 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(macro f1): [0 1 1 0]\n",
      "\n",
      "Tweet: I know, its just harder than I thought living with my parents driving me up a wall.  When I was working; I was fine because I would literally be working 10-12 hours a day, get home, make something to eat, watch some Netflix or play video games, go to sleep, and repeat.  Not a whole lot of interactions except to organize a family movie night at a theater with my brother as well and not having it be so late for us to still go to bed and wake up the next morning at 5 or so...\n",
      "\n",
      "Now I'm taking some online classes in computer science and business so I can hopefully learn and be able land something to be able to still work from home and making a pay check next time something like this happens.  I work for a wholesale business that delivers liquor to bars and restaurants - but when they shut down, business went down as well and we were out of a job for a week.  Luckily, our boss was also opening up 2 new stores before all this and is giving us some work to do to both help them out as well as us whenever this clears out and we can hit the ground running better prepared.  They're still going to pay us our full amount that we were getting before, just a different kind of work.  Still work.\n",
      "['Gold Standards- Technology', 'Gold Standards- Ride Share', 'Gold Standards- Food Delivery', 'Gold Standards- Online Shopping']\n",
      "Ground-Truth Class: [0, 0, 1, 0]\n",
      "Lexicon Exclamation Model Prediction(micro f1): [0 0 0 0]\n",
      "Lexicon Exclamation Model Prediction(macro f1): [0 0 0 0]\n",
      "Lexicon Technology Word Count Model Prediction(macro f1): [0 0 0 0]\n",
      "Lexicon Technology Word Count Model Prediction(micro f1): [0 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(macro f1): [1 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(micro f1): [0 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(macro f1): [0 0 0 0]\n",
      "\n",
      "Tweet: I'm really stuck as to where to begin, but I'll stay brief:\n",
      "\n",
      "You officially rationalized intrusion. Even if it is as you say it is (it isn't), it doesn't make up for the principal of the fact. True, google's algorithms can figure out a lot. Wtf do you think the government is using?! Bringing up how bad other governments are doesn't make what the government is doing \"okay\". If anything, the government knows that keeping it's people comfortable allows them far more freedom to fuck over other countries than if they wanted to treat us like they were N.Korea.\n",
      "\n",
      "People will fight for their fake \"freedom\" (usa) a lot harder than for an imposing government (n.korea) (staying within the confines of your examples).\n",
      "\n",
      "This all goes much deeper, and we're hardly doing any side of the argument justice, here. If it was as you say it is, the bevy of guilty companies being mined wouldn't be as high as it is.\n",
      "['Gold Standards- Technology', 'Gold Standards- Ride Share', 'Gold Standards- Food Delivery', 'Gold Standards- Online Shopping']\n",
      "Ground-Truth Class: [1, 0, 0, 0]\n",
      "Lexicon Exclamation Model Prediction(micro f1): [1 0 0 1]\n",
      "Lexicon Exclamation Model Prediction(macro f1): [1 0 0 1]\n",
      "Lexicon Technology Word Count Model Prediction(macro f1): [1 0 0 0]\n",
      "Lexicon Technology Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(macro f1): [1 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(macro f1): [1 0 0 0]\n",
      "\n",
      "Tweet: USAA is a great choice. I worked there for two years. They dont have the most modern or fast paced environment (banking regulations = slow) . Their technology stack is actually better than most other banks and the people who work there are pretty smart cookies. One of my former coworker could easily have worked at Google. The pay is subpar but for a first job its 11/10 when it comes to benefits and culture. Your manager cares about you and your coworkers always want you to grow.\n",
      "['Gold Standards- Technology', 'Gold Standards- Ride Share', 'Gold Standards- Food Delivery', 'Gold Standards- Online Shopping']\n",
      "Ground-Truth Class: [1, 0, 0, 0]\n",
      "Lexicon Exclamation Model Prediction(micro f1): [1 0 1 1]\n",
      "Lexicon Exclamation Model Prediction(macro f1): [1 0 1 1]\n",
      "Lexicon Technology Word Count Model Prediction(macro f1): [1 0 1 1]\n",
      "Lexicon Technology Word Count Model Prediction(micro f1): [1 0 1 1]\n",
      "Lexicon Online App Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(macro f1): [1 0 1 1]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(micro f1): [1 0 1 1]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(macro f1): [1 0 1 1]\n",
      "\n",
      "Tweet: USAA is a great choice. I worked there for two years. They dont have the most modern or fast paced environment (banking regulations = slow) . Their technology stack is actually better than most other banks and the people who work there are pretty smart cookies. One of my former coworker could easily have worked at Google. The pay is subpar but for a first job its 11/10 when it comes to benefits and culture. Your manager cares about you and your coworkers always want you to grow.\n",
      "['Gold Standards- Technology', 'Gold Standards- Ride Share', 'Gold Standards- Food Delivery', 'Gold Standards- Online Shopping']\n",
      "Ground-Truth Class: [1, 0, 0, 0]\n",
      "Lexicon Exclamation Model Prediction(micro f1): [1 0 0 1]\n",
      "Lexicon Exclamation Model Prediction(macro f1): [1 0 0 1]\n",
      "Lexicon Technology Word Count Model Prediction(macro f1): [1 0 0 1]\n",
      "Lexicon Technology Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(macro f1): [1 0 0 1]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(micro f1): [1 0 0 1]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(macro f1): [1 0 0 1]\n",
      "\n",
      "Tweet: Apparently Reddit is Facebook now...\n",
      "['Gold Standards- Technology', 'Gold Standards- Ride Share', 'Gold Standards- Food Delivery', 'Gold Standards- Online Shopping']\n",
      "Ground-Truth Class: [1, 1, 0, 0]\n",
      "Lexicon Exclamation Model Prediction(micro f1): [0 0 0 0]\n",
      "Lexicon Exclamation Model Prediction(macro f1): [0 0 0 0]\n",
      "Lexicon Technology Word Count Model Prediction(macro f1): [0 0 0 0]\n",
      "Lexicon Technology Word Count Model Prediction(micro f1): [0 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(micro f1): [0 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(macro f1): [0 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(micro f1): [0 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(macro f1): [0 1 0 0]\n",
      "\n",
      "Tweet: Y'all are aware that he's a Senator who spends 90% of his time away from Texas (in DC) anyway, right?  Was he supposed to fly down here and freeze with us in unity?  Come down here and take up even more gas, water and power resources that we don't have?  lol, c'mon now.   It would be one thing if there was actually something of substance for him to do down here. But there really isn't.   All he can do is make phone calls and send emails.  And he can do that from anywhere.\n",
      "['Gold Standards- Technology', 'Gold Standards- Ride Share', 'Gold Standards- Food Delivery', 'Gold Standards- Online Shopping']\n",
      "Ground-Truth Class: [0, 1, 0, 0]\n",
      "Lexicon Exclamation Model Prediction(micro f1): [1 0 0 1]\n",
      "Lexicon Exclamation Model Prediction(macro f1): [1 0 0 1]\n",
      "Lexicon Technology Word Count Model Prediction(macro f1): [0 0 0 0]\n",
      "Lexicon Technology Word Count Model Prediction(micro f1): [0 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(macro f1): [1 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(micro f1): [0 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(macro f1): [0 0 0 0]\n",
      "\n",
      "Tweet: They aren't officially open until Jan, but these folks are great.  Highly recommend!\n",
      "\n",
      "https://www.facebook.com/hqmobilesalon\n",
      "['Gold Standards- Technology', 'Gold Standards- Ride Share', 'Gold Standards- Food Delivery', 'Gold Standards- Online Shopping']\n",
      "Ground-Truth Class: [1, 1, 1, 0]\n",
      "Lexicon Exclamation Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Exclamation Model Prediction(macro f1): [1 0 0 0]\n",
      "Lexicon Technology Word Count Model Prediction(macro f1): [1 0 0 0]\n",
      "Lexicon Technology Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(macro f1): [1 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(macro f1): [1 0 0 0]\n",
      "\n",
      "Tweet: This is patently false, Harris and Dallas counties have much higher rates.\n",
      "\n",
      "Source: https://txdshs.maps.arcgis.com/apps/opsdashboard/index.html#/ed483ecd702b4298ab01e8b9cafc8b83\n",
      "\n",
      "And you dare smear our beautiful rivers, you self-loathing miser?\n",
      "['Gold Standards- Technology', 'Gold Standards- Ride Share', 'Gold Standards- Food Delivery', 'Gold Standards- Online Shopping']\n",
      "Ground-Truth Class: [0, 1, 1, 0]\n",
      "Lexicon Exclamation Model Prediction(micro f1): [0 0 0 0]\n",
      "Lexicon Exclamation Model Prediction(macro f1): [0 0 0 0]\n",
      "Lexicon Technology Word Count Model Prediction(macro f1): [0 0 0 0]\n",
      "Lexicon Technology Word Count Model Prediction(micro f1): [0 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(micro f1): [1 0 0 0]\n",
      "Lexicon Online App Word Count Model Prediction(macro f1): [1 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(micro f1): [0 0 0 0]\n",
      "Lexicon Food Delivery App Word Count Model Prediction(macro f1): [0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manual analysis of the predictions to verify:\n",
    "num_tweets = 0\n",
    "for comment,logistic_Xtest_prediciton_micro_f_em,logistic_Xtest_prediciton_macro_f_em,logistic_Xtest_prediciton_macro_f_twc,logistic_Xtest_prediciton_micro_f_twc,logistic_Xtest_prediciton_micro_f_olp,logistic_Xtest_prediciton_macro_f_olp,logistic_Xtest_prediciton_micro_f_fda,logistic_Xtest_prediciton_macro_f_fda,y  in zip(X_txt,logistic_X_test_prediciton_micro_f_em,logistic_X_test_prediciton_macro_f_em,logistic_X_test_prediciton_macro_f_twc,logistic_X_test_prediciton_micro_f_twc,logistic_X_test_prediciton_micro_f_olp,logistic_X_test_prediciton_macro_f_olp,logistic_X_test_prediciton_micro_f_fda,logistic_X_test_prediciton_macro_f_fda, y_test):\n",
    "    print(\"Tweet: {}\".format(comment))\n",
    "    print(header[2:6])\n",
    "    print(\"Ground-Truth Class: {}\".format(y))\n",
    "    print(\"Lexicon Exclamation Model Prediction(micro f1): {}\".format(logistic_Xtest_prediciton_micro_f_em))\n",
    "    print(\"Lexicon Exclamation Model Prediction(macro f1): {}\".format(logistic_Xtest_prediciton_macro_f_em))\n",
    "    print(\"Lexicon Technology Word Count Model Prediction(macro f1): {}\".format(logistic_Xtest_prediciton_macro_f_twc))\n",
    "    print(\"Lexicon Technology Word Count Model Prediction(micro f1): {}\".format(logistic_Xtest_prediciton_micro_f_twc))\n",
    "    print(\"Lexicon Online App Word Count Model Prediction(micro f1): {}\".format(logistic_Xtest_prediciton_micro_f_olp))\n",
    "    print(\"Lexicon Online App Word Count Model Prediction(macro f1): {}\".format(logistic_Xtest_prediciton_macro_f_olp))\n",
    "    print(\"Lexicon Food Delivery App Word Count Model Prediction(micro f1): {}\".format(logistic_Xtest_prediciton_micro_f_fda))\n",
    "    print(\"Lexicon Food Delivery App Word Count Model Prediction(macro f1): {}\".format(logistic_Xtest_prediciton_macro_f_fda))\n",
    "    print()\n",
    "    \n",
    "    num_tweets += 1\n",
    "    if num_tweets == 10:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
